{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "Jonathan Jalbert<br/>\n",
    "Professeur agrégé au Département de mathématiques et de génie industriel<br/>\n",
    "Polytechnique Montréal<br/>\n",
    "\n",
    "\n",
    "## TD10 : Mélanges de lois : Classification du rayon des tumeurs\n",
    "\n",
    "Les données du concours A2020 sont utilisées.\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Une tumeur est un groupe de cellules anormales qui forment une masse. Les tumeurs se développent et se comportent différemment, selon qu’elles soient cancéreuses (malignes), non cancéreuses (bénignes). Le but du concours était de prédire si une tumeur est bénigne (0) ou maligne (1) en fonction des caractéristiques suivantes récoltées par imagerie médicale : \n",
    "\n",
    "- radius : distance moyenne entre le centre de la tumeur et son périmètre ;\n",
    "- texture : écart-type des niveaux de gris représentant l'image de la tumeur ;\n",
    "- perimeter : périmètre de la tumeur ;\n",
    "- area : superficie de la tumeur ;\n",
    "- smoothness : variation locale normalisée en fonction du radius (indice de rugosité) ;\n",
    "- compactness : perimeter^2 / area -1 (indice de compacité) ;\n",
    "- symmetry : mesure de symétrie ; \n",
    "- fractal dimension : (\"coastline approximation\" - 1).\n",
    "\n",
    "Dans ce TD, nous modéliserons le rayon des tumeurs par un mélange de lois normales. On s'attend à ce que le rayon des tumeurs bénignes soient distribués selon une loi normale et que le rayon des tumeurs malignes soient distribués selon une autre loi normale. On pourra donc utiliser le mélange de lois pour classer les tumeurs à l'aide d'une seule variable : son rayon.\n",
    "\n",
    "## Objectifs du TD\n",
    "\n",
    "Ce TD est composé de trois exercices. Le premier exercice permet d'explorer les données. Le deuxième modélise une caractéristique des tumeurs, soit la rayon, avec un mélange de deux lois normales. Le troisième exercice permet de prédire la classe de la tumeur (bénigne ou maligne) en fonction des composantes du mélange ajusté.\n",
    "\n",
    "Plusieurs fonctions vous sont fournies pour vous faciliter la tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Distributions, Gadfly, MLBase, Random, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    GMM(ω::Real, μ₀::Real, σ₀::Real, μ₁::Real, σ₁::Real)\n",
    "\n",
    "Création d'un objet de type `UnivariateMixture` de la librairie *Distributions.jl* ayant comme densité\n",
    "\n",
    "```math\n",
    "f(y) = (1-ω) ~ \\\\mathcal{N}( y\\\\mid μ₀, σ₀²) + ω ~ \\\\mathcal{N}( y\\\\mid μ₁, σ₁²)\n",
    "```\n",
    "\"\"\"\n",
    "function GMM(ω::Real, μ₀::Real, σ₀::Real, μ₁::Real, σ₁::Real)\n",
    "    \n",
    "    pd = MixtureModel(Normal[ Normal(μ₀, σ₀), Normal(μ₁, σ₁)], [1-ω, ω])\n",
    "    \n",
    "    return pd\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    componentprob(mixturemodel::UnivariateMixture, y::Real; componentindex=1, logprob=false)\n",
    "\n",
    "Calcul de la probabilité que y provienne de la composante `componentindex` du mélange `mixturemodel`.\n",
    "\"\"\"\n",
    "function componentprob(mixturemodel::UnivariateMixture, y::Real; componentindex=1, logprob=false)\n",
    "\n",
    "    fc = component(mixturemodel,componentindex)\n",
    "    \n",
    "    lp = log(probs(mixturemodel)[componentindex]) + logpdf(fc,y) - logpdf(mixturemodel, y)\n",
    "    \n",
    "    if logprob\n",
    "        return lp\n",
    "    else\n",
    "        return exp(lp)\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    _emstep(pd::MixtureModel,y)\n",
    "\n",
    "Réalisation d'une itération de l'algorithme EM à partir du mélange `pd` avec les données `y`.\n",
    "\n",
    "#### Détails\n",
    "La fonction met à jour les paramètres de la distribution `pd` avec les estimations améliorées.\n",
    "\"\"\"\n",
    "function _emstep(pd::MixtureModel,y)\n",
    "    \n",
    "    n = length(y)\n",
    "    \n",
    "    f₁ = component(pd, 2)\n",
    "    ω = probs(pd)[2]\n",
    "    \n",
    "    lp₁ = log(ω) .+ logpdf.(f₁,y) - logpdf.(pd, y)\n",
    "    p₁ = exp.(lp₁)\n",
    "    \n",
    "    ω̂ = sum(p₁)/n\n",
    "    \n",
    "    p₀ = 1 .- p₁\n",
    "    \n",
    "    μ̂₀ = sum( p₀.* y) / sum(p₀)\n",
    "    \n",
    "    σ̂₀² = sum( p₀.* (y .- μ̂₀).^2 ) / sum(p₀)\n",
    "    \n",
    "    μ̂₁ = sum( p₁.* y) / sum(p₁)\n",
    "    \n",
    "    σ̂₁² = sum( p₁.* (y .- μ̂₁).^2 ) / sum(p₁)\n",
    "    \n",
    "    fd = GMM(ω̂, μ̂₀, sqrt(σ̂₀²), μ̂₁, sqrt(σ̂₁²))\n",
    "    \n",
    "    return fd\n",
    "    \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    GMMemfit(y::Vector{<:Real} ; initialvalue::Vector{<:Real}=Float64[], maxiter::Int=1000, tol::Real=2*eps())\n",
    "\n",
    "Calcul des estimateurs du maximum de la vraisemblance d'un mélange de lois normales avec l'algorithme EM.\n",
    "\"\"\"\n",
    "function GMMemfit(y::Vector{<:Real} ; initialvalue::Vector{<:Real}=Float64[], maxiter::Int=1000, tol::Real=2*eps())\n",
    "    \n",
    "    if isempty(initialvalue)\n",
    "        \n",
    "        n = length(y)\n",
    "        \n",
    "        ind = (1:n) .< n/2\n",
    "        \n",
    "        y₀ = y[ind]\n",
    "        y₁ = y[.!(ind)]\n",
    "        \n",
    "        initialvalue = [.5, mean(y₀), std(y₀), mean(y₁), std(y₁)]\n",
    "        \n",
    "    end\n",
    "    \n",
    "    pd = GMM(initialvalue...)\n",
    "    \n",
    "    iter = 1\n",
    "    err = 1\n",
    "    \n",
    "    while (err > tol) & (iter < maxiter)\n",
    "       \n",
    "        fd = _emstep(pd,y)\n",
    "        \n",
    "        err = abs(loglikelihood(fd,y) - loglikelihood(pd,y))\n",
    "        \n",
    "        pd = fd\n",
    "        \n",
    "        iter +=1\n",
    "        \n",
    "    end\n",
    "    \n",
    "    μ₀ = mean(components(pd)[1])\n",
    "    μ₁ = mean(components(pd)[2])\n",
    "\n",
    "    if μ₀ > μ₁\n",
    "        μ₀ = mean(components(pd)[2])\n",
    "        σ₀ = std(components(pd)[2])\n",
    "        μ₁ = mean(components(pd)[1])\n",
    "        σ₁ = std(components(pd)[1])\n",
    "        ω = probs(pd)[1]\n",
    "\n",
    "        pd = GMM(ω, μ₀, σ₀, μ₁, σ₁)\n",
    "\n",
    "    end\n",
    "    \n",
    "    \n",
    "    \n",
    "    if iter == maxiter\n",
    "        println(\"Convergence not reached in $maxiter iterations\")\n",
    "    else\n",
    "        println(\"Convergence reached in $iter iterations\")\n",
    "    end\n",
    "    \n",
    " return pd\n",
    "    \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    histplot(fd::UnivariateMixture, y::Vector{<:Real})\n",
    "\n",
    "Trace le mélange de lois `fd` superposé à l'histogramme des données `y`.\n",
    "\"\"\"\n",
    "function histplot(fd::UnivariateMixture, y::Vector{<:Real})\n",
    "   \n",
    "    @assert length(components(fd)) == 2 \"the function is optimized for a mixture of two components.\"\n",
    "    \n",
    "    nbin = floor(Int,sqrt(length(y)))\n",
    "    opacity = repeat([0.75, 0.85], outer=nbin)\n",
    "    \n",
    "    xmin = minimum(y)\n",
    "    xmax = maximum(y)\n",
    "       \n",
    "    plot(Guide.ylabel(\"densité\"), Guide.xlabel(\"y\"), Coord.cartesian(xmin=xmin, xmax=xmax),\n",
    "        layer(x -> pdf(fd, x), xmin , xmax, Theme(default_color=\"black\")),\n",
    "        layer(x -> probs(fd)[1]*pdf(components(fd)[1], x), xmin , xmax, Geom.line, Theme(default_color=\"gold2\")),\n",
    "        layer(x -> probs(fd)[2]*pdf(components(fd)[2], x), xmin , xmax, Theme(default_color=\"red\")),\n",
    "        layer(x=y, alpha=opacity, Geom.histogram(position=:identity, bincount = nbin, density=true)),\n",
    "    )\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "\n",
    "On charge les données de l'ensemble d'entraînement du concours, soit les caractéristiques des mesurées des tumeurs malignes et bénignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"COLUMNS\"] = 1000;  # pour voir toutes les colonnes\n",
    "\n",
    "data = CSV.read(\"train.csv\", DataFrame)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitionnement des données en ensemble d'entraînement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(data), round(Int, .8*nrow(data)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(data), train_id)\n",
    "\n",
    "train = data[train_id,:]\n",
    "valid = data[valid_id,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 - Analyse exploratoire partielle\n",
    "\n",
    "Analyse exploratoire partielle de l'ensemble d'entraînement.\n",
    "\n",
    "### (a) Tracez l'histogramme illustrant le rayon des tumeurs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour définir le nombre de bins\n",
    "nbin = floor(sqrt(length(train.radius)))\n",
    "\n",
    "# Pour régler les dimensions du graphique\n",
    "set_default_plot_size(12cm, 8cm)\n",
    "\n",
    "plot(train, x=:radius, Geom.histogram(bincount=nbin))  # avec un DataFrame\n",
    "\n",
    "#plot(x=train.radius, Geom.histogram(bincount=nbin))  # avec un vecteur \n",
    "\n",
    "# Ici, on peut presque déjà apercevoir deux groupes, un autour de 12-13 et l'autre vers 18-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Calculez la proportion de tumeurs malignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si maligne, train.diagnosis = 1\n",
    "# si bénigne, train.diagnosis = 0\n",
    "\n",
    "mean(train.diagnosis)  # version simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(train.diagnosis .== 1) / length(train.diagnosis)  # La version longue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculez la moyenne et l'écart-type du rayon en fonction de la classe de la tumeur\n",
    "\n",
    "Vous pouvez utiliser les fonctions `groupby()` et `combine()`pour des opérations rapides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine(groupby(train, :diagnosis), # on groupe les données selon :diagnosis,\n",
    "    \n",
    "        :radius => mean => :moyenne,  # colonne radius, on calcule la moy. et on la passe dans une nouv. col.\n",
    "       \n",
    "        :radius => std => :ecarttype # puis on fait la même chose avec l'écart-type\n",
    "    \n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Tracez des diagrammes en boîtes des rayons en fonction de la classe des tumeurs\n",
    "\n",
    "Utilisez la géométrie `Geom.boxplot()` de *Gadfly.jl*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(train, x=:diagnosis, y=:radius,  Geom.boxplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 - Modélisation du rayon par un mélange de lois\n",
    "\n",
    "Modélisation du rayon des tumeurs (`:radius`) avec un mélange de lois de deux lois normales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Estimez les paramètres du mélange de lois normales modélisant le rayon des tumeurs\n",
    "\n",
    "Utilisez l'algorithme EM pour trouver les estimations du maximum de la vraisemblance.\n",
    "\n",
    "Vous pouvez utiliser la fonction `GMMemfit()` fournie qui renvoie un objet de type `GMM` (aussi fourni)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = GMMemfit(train.radius)  # la fonction prend le vecteur des rayons en entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Tracez le mélange de lois superposé à l'histogramme des données\n",
    "\n",
    "Vouz pouvez utiliser la fonction `histplot()` fournie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histplot(fd, train.radius)  # beau mélange de lois normales ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Décrivez les composantes obtenues\n",
    "\n",
    "**Note :** L'objet `GMM` est de type `UnivariateMixture` de la librairie *Distributions.jl*. On peut utiliser les méthodes standards de la librairie tel `pdf()` et `logpdf()` sur le type `UnivariateMixture`. Les méthodes suivantes sont particulières au type `UnivariateMixture` :\n",
    "- `probs(fd::UnivariateMixture)` : retourne le vecteur des poids de chacune des composantes ;\n",
    "- `component(fd::UnivariateMixture, k)` : retourne un objet de type `Distribution` correspondant à la composante k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, la composante 1 a un poids de 68%  et la composante 2, 32%\n",
    "probs(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la composante 1, la moyenne et l'écart-type de la loi Normale sont :\n",
    "component(fd, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la composante 2, la moyenne et l'écart-type de la loi Normale sont :\n",
    "component(fd, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Est-ce que les paramètres obtenus sont cohérents avec les questions (b) et (c) de l'exercice 1 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  # Oui ! Ça ressemble beaucoup à ce qu'on avait obtenu...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3 - Classification des tumeurs\n",
    "\n",
    "Utilisation du mélange de lois pour classifier les tumeurs entre bénignes et malignes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Calculez les probabilités que les observations proviennent de la 2e composante du mélange.\n",
    "\n",
    "Calculez ces probabilités pour les observations des l'ensemble d'entraînement.\n",
    "\n",
    "Vous pouvez utiliser la fonction `componentprob()` fournie pour calculer ces probabilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = componentprob.(fd, train.radius, componentindex=2);\n",
    "\n",
    "              #  ↑ . pour le faire sur tout le vecteur de rayons train.radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p  # on obtient un vecteur de prob de 364 éléments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Prédisez les classes des tumeurs en fonction des probabilités calculées aux numéros précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j'initialise un vecteur de zéro de la même taille que le nombre de tumeurs (364)\n",
    "ŷ = Int.(zeros(length(train.diagnosis))) ; \n",
    "\n",
    "# si la prob d'apartenir à la composant 2 est supérieure à 0.5, je classe la tumeur comme étant maligne\n",
    "ŷ[p .> 0.5] .= 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculez les qualités des prédictions obtenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.diagnosis  # le vrai diagnostic \n",
    "\n",
    "r = roc(y, ŷ)  # on calcule la ROC avec la fonction roc() de MLBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Sur l'ensemble d'entraînement\")\n",
    "println(\"- Nombre de tumeurs malignes bien identifiées : \",r.tp)\n",
    "println(\"- Nombre de tumeurs bénignes bien identifiées : \",r.tn)\n",
    "println(\"- Nombre de tumeurs malignes identifiées comme bénignes : \",r.fn)\n",
    "println(\"- Nombre de tumeurs bénignes identifiées comme malignes : \",r.fp)\n",
    "println(\"- Le score F₁ est de : \", round(f1score(r), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Répétez les étapes pour obtenir les prédictions sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on calcule maitenant le prob d'appartenir à la composante 2 de fd (fitté sur train) avec les rayons de valid\n",
    "p = componentprob.(fd, valid.radius, componentindex=2); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j'initialise un vecteur de zéro de la même taille que le nombre de tumeurs (de valid)\n",
    "ŷ = Int.(zeros(length(valid.diagnosis)))  \n",
    "\n",
    "# si la prob d'apartenir à la composant 2 est supérieure à 0.5, je classe la tumeur comme étant maligne\n",
    "ŷ[p .> 0.5] .= 1 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = valid.diagnosis  # le vrai diagnostic (de valid)\n",
    "\n",
    "r = roc(y, ŷ)  # on calcule la ROC avec la fonction roc() de MLBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Sur l'ensemble d'entraînement\")\n",
    "println(\"- Nombre de tumeurs malignes bien identifiées : \",r.tp)\n",
    "println(\"- Nombre de tumeurs bénignes bien identifiées : \",r.tn)\n",
    "println(\"- Nombre de tumeurs malignes identifiées comme bénignes : \",r.fn)\n",
    "println(\"- Nombre de tumeurs bénignes identifiées comme malignes : \",r.fp)\n",
    "println(\"- Le score F₁ est de : \", round(f1score(r), digits=4))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
